---
title: 'Mapping Mangrove Growth and Deforestation with Satellite Imagery'
date: 2021-03-21
permalink: /posts/2021/03/blog-mapping-mangroves/
tags:
  - data science
  - neural network
  - satellite imagery
---

![](/images/mangrove_project_blog/Mangroves1.png)


*Note: This blog is a work in progress.*

For my final [Metis](https://www.thisismetis.com/) data science boot camp project, I knew I wanted to get some experience using neural networks on image data. After going back and forth on all sorts of ideas (who doesn't when they are trying to come up with an interesting, but do-able, project?), I ultimately landed on classifying mangrove forests using satellite imagery.

<!-- I decided to create a mangrove forest classifier from a neural network trained on satellite imagery.  -->


## Mangrove Forests

Mangroves are salt-tolerant, tropical trees which live and thrive along warm coastal waters. There is around 135,000 square kilometers of mangrove forested areas around the world. These mangrove forests store 4-10 times more carbon than ordinary land forests, protect shorelines against storms, filter pollutants from the ocean waters, and provide natural habitats for many species. These mangrove domains are under threat from both climate change and man-made sources. Per the [Global Mangrove Alliance](http://www.mangrovealliance.org/mangrove-knowledge/), these mangrove forests are being degraded at about 1% per year globably. In some cases, like the south of Florida or Myanmar the degradation is even worse. Monitoring, tracking, and protecting these mangroves is a vital task for protecting our environment on both a global and a local scale.


![](/images/mangrove_project_blog/Manatee.jpeg)



## Satellite Monitoring

Satellite imagery can be used for remote monitoring of mangroves worldwide. This approach has been used more and more in recent years, with a lot of advanced efforts going on. [This article](https://medium.com/google-earth/mangrove-monitoring-in-google-earth-engine-4d6f6be8d7fc) on Medium summarizes a number of different use cases around the world and the ongoing work for them.


Google Earth Engine (GEE) is a powerful tool which allows free access to a wealth of satellite imagery going back years. Given the time constraints (about 3 weeks) and having no prior knowledge of the subject or satellite data, this was a perfect resource for my project. GEE has a straightforward API for accessing said satellite imagery and outputting information and images of interest. Specifically, I was able to locate a map of mangrove forests mapped around the world by [C. Giri et al.](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1466-8238.2010.00584.x) for the year 2000. Using satellite images from the year 2000 which corresponded to the mapped out mangroves, I could train a classifier to recognize those mangroves. I could then acquire satellite images from more recent years such as 2020, and do a comparison of the before and after to see the level of deforestation and growth. 


![](/images/mangrove_project_blog/MangroveMap.png)


I decided to focus on one area of interest, that being the Florida coastline. There are over 60 mangrove species around the world with different physical characteristics. In my exploratory data analysis phase of the project I did test out other locations such as places in Brazil, Cuba, and Cameroon. In some instances the trained model performed well in other locations, while in some instances it did not. I decided to restrict my project to a single area where the satellite image colors were consistent, and my project could be more focused and contained.



## The Data

I started my project by learning how to use the GEE API along with a little bit of JavaScript along the way. The process is relatively simple: you load collections of satellite images, filter those images by time or location, composite several images together in order to create a single image, and lastly export that image to somewhere like Google Drive. (You can find [here](https://geohackweek.github.io/GoogleEarthEngine/) a very nice website which provides tutorials on how to get started. I found the section "Accessing Satellite Imagery" particularly useful.)


From my research I knew that the labeled mangrove map was built on Landsat 5 satellite data. Because I wanted to compare 2020 satellite imagery results to classified results from the year 2000, I knew I needed current satellite imagery. Landsat 5 was decommissioned in 2013, so I was left with either choosing Landsat 7 or Landsat 8 data. I chose Landsat 7 data, because it was active in the year 2000 and was still active in 2020. This gave me the ability to train a model using the same satellite system data as the data I would then later predict on. 


<!-- (I thought about using Landsat 8, and indeed that might prove better for the 2020 data as I never tested it, however the data specifications are different and I was therefore worried that my predictive model would not properly transfer.)  -->


<!-- ![](/images/mangrove_project_blog/Satellite.png) -->
<img src="/images/mangrove_project_blog/Satellite.png" width="200"/>


Landsat 7 data has a resolution of 30 meters per pixel, and contains information in 8 different bands. These are the standard RGB bands, a near infrared bed, 2 shortwave infrared bands, a thermal band, and a panchromatic band. (I decided to drop this last band since the resolution was 15 meters, different to the 30 meter resolution of the other bands, and would complicate my analysis without adding much gain.) **To be clear about my project now, I was now going to do a pixel-wise classification of satellite imagery as mangrove forest or not, using these 7 bands as my features.**


## Satellite Image Compositing


Using a single satellite image by itself for the data would not work, as certain areas are captured only once every 8 to 16 days. Beyond that, in every image there will be clouds, cloud shadows, and potentially artifacts which obscure parts of the image. In order to get around this, GEE has some nice functionality to composite a single image from many other images based on various features. Using this functionality, I composited images from the whole year for the years 2000 and 2020 in order to mask out pixels which contained these clouds or artifacts in order to get pure land and water pixels.


But how did I select which composited image from which to grab the pixel from? If multiple satellite images contained the same pixel with no clouds in the way, then there is an issue of ambiguity. I selected those pixels which had the maximum NDVI values for all identical pixels in all the composited images. NDVI here stands for "normalized difference vegetation index," and provides a standard measure for the amount of living green vegetation contained within a pixel. (Specifically NDVI is calculated from the near-infrared and red bands.) Selecting on the maximum NDVI satisfied a dual purpose, in that it also allowed me to select those pixels corresponding to mangrove forests at the height of the growth season, and account for changing seasons and conditions. (This approach is nicely suited for gathering images worldwide as well, though I only focused on one region of interest.) The image below shows an RGB image of a part of the Florida coastline, then overlaid with the NDVI band colored as green, then overlaid with the labeled mangrove forests from the aforementioned map. As you can see, the darkest green parts of the image correspond directly with the labeled mangrove forests.


![](/images/mangrove_project_blog/Florida_1_CNN_input.gif)


## Models


For the classification model, I tested out two neural network models. I had a lot of help and took a lot of inspiration from two tutorials by P. Tripathy, [here](https://towardsdatascience.com/neural-network-for-satellite-data-classification-using-tensorflow-in-python-a13bcf38f3e1) and [here](https://towardsdatascience.com/is-cnn-equally-shiny-on-mid-resolution-satellite-data-9e24e68f0c08). They were a nice introduction to getting started with neural networks on satellite imagery. 


The first model was a basic neural network with just two layers, and 14 nodes per layer. The input to this model was the information contained within a single pixel, ie. 7 numbers for the 7 different bands per pixel. This baseline model could almost certainly have been done with just a random forest classifier, but I wanted to get my feet wet with neural networks right off the bat, even if it was overkill.


The second model was a convolutional neural network, taking as input the pixel information in a 7x7 grid around the target pixel. This would help with the classification of the pixel at the center of this grid. For the model architecture I started with the code as given in one of the above linked tutorials, and then tried out various alternatives to eke out a bit more precision and recall. I ultimately used two convolutional layers, several dropout layers, and a dense layer. The dropout layers nicely prevented overfitting, and no pooling layer was included because I was not trying to pick out a specific object from the image. (Since I'm still new to this, it may be true that pooling layers might still be useful for this use case.)



![](/images/mangrove_project_blog/CNN_model_input.png)


```python

model = keras.Sequential()
model.add(Conv2D(32, kernel_size=3, padding='valid', activation='relu', input_shape=(7, 7, 7)))
model.add(Dropout(0.25))
model.add(Conv2D(48, kernel_size=3, padding='valid', activation='relu'))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(2, activation='softmax'))

model.compile(optimizer= 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy', 'recall'])
```


## Results


Ultimately, I chose to optimize my model on F1 score, since I cared about both the precision and recall of the positive class equally. 



| F1 Scores    | Basic NN    | CNN    |
| :----------- | :-----------: | :-----------: |
| Test Data          | 0.871 | 0.914 |
| Separate Image 1   | 0.911 | 0.921 |
| Separate Image 2   | 0.870 | 0.901 |


![](/images/mangrove_project_blog/ROC_Florida_1_2000.png)




![](/images/mangrove_project_blog/PvA_Florida_1_2000.png)
![](/images/mangrove_project_blog/PvA_Florida_4_2000.png)

![](/images/mangrove_project_blog/GaL_Florida_1_2020.png)
![](/images/mangrove_project_blog/GaL_Florida_4_2020.png)


![](/images/mangrove_project_blog/Florida_1_CNN_full.gif)
<!-- ![](/images/mangrove_project_blog/Florida_4_CNN_full.gif)
![](/images/mangrove_project_blog/Florida_5_CNN_full.gif)
![](/images/mangrove_project_blog/Florida_6_CNN_full.gif) -->





## Conclusions and Future Work



- unet
rnn

- maybe put an image of some more mangroves






[medium 2020 article](https://medium.com/uk-hydrographic-office/scaling-machine-learning-models-across-the-globe-the-quest-for-geo-generalisability-in-mangrove-f14282738378) by the UKHO (Hydrographic Office) doing machine learning across the globe with generalized models


[2019 article](https://www.intechopen.com/books/geographic-information-systems-and-science/gis-and-remote-sensing-for-mangroves-mapping-and-monitoring) by blank mapping mangroves in Malaysia


[Global Mangrove Alliance](http://www.mangrovealliance.org/mangrove-knowledge/) website with details and their 
[Global Mangrove Watch](https://www.globalmangrovewatch.org/?map=eyJiYXNlbWFwIjoibGlnaHQiLCJ2aWV3cG9ydCI6eyJsYXRpdHVkZSI6MjAsImxvbmdpdHVkZSI6MCwiem9vbSI6Mn19) web portal for tracking mangroves around the world


[GEEMMM](https://github.com/Blue-Ventures-Conservation/GEEMMM) github project (Google Earth Engine Mangrove Mapping Methodology) for mapping mangroves funded by Blue Ventures Conservation with funding from UK Governmentâ€™s International Climate Fund


these are only some, there are others...




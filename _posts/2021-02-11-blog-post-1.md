---
title: 'A Dip into Machine Learning Applications in Particle Physics'
date: 2021-02-17
permalink: /posts/2021/02/blog-machine-learning-particle-physics/
tags:
  - physics
  - data science
  - machine learning
---

Note: This blog is currently a work in progress.

![](/images/particle_investigation_blog/ColorfolParticlesImage.png)


As part of the Metis data science boot camp, we were required to investigate a topic and then present on it. With my background detailed on the main page, it's no surprise that I was interested in learning a little bit more about machine learning applications in particle physics. While I never did any machine learning work as part of my graduate degree, it's always been interesting to me so I thought I would take advantage of the opportunity.

Please note that I am not an expert in this subject. Most of the material I will go through here has come from a lot of online searches. At the end of this post is included a list of sources I found very educational, which I took inspiration (and a few plots) from. If you spot any misrepresentations in the material below, please do not hesitate to reach out to me so that I can correct them.




<!-- Some other fantastic presentations include [this one](https://indico.in2p3.fr/event/17429/attachments/47800/62191/2018-06-22_ML_Introduction_Haake.pdf) by R. Haake and [this one](https://indico.fnal.gov/event/15893/contributions/34315/attachments/21384/26602/Fermilab_ML_Lecture1.pdf) by M. Williams.
 -->


## What is particle physics and why use machine learning?
<!-- ====== -->

Particle physics is the study of the basic blocks of matter. While there are smaller experiments located around the world, the majority of research is driven by large accelerators and particle colliders. These accelerators crash particles into each other or into some material in order to produce new interesting particles and interactions. By measuring what happens after the collisions with various **experiments**, physicists can derive the underlying laws which govern our universe. Collisions happen many times a second as these accelerators run, and the experiments gather an astronomical amount of data every second. And as any one learning about the data science and machine learning world knows, a wealth of data is exactly where machine learning becomes really useful.

<!-- ![](/images/particle_investigation_blog/CERN_Tunnel.png) -->

| ![](/images/particle_investigation_blog/CERN_Tunnel.png) |
|:-------------------------:|
| Beamline tunnel at CERN in France and Switzerland. |


In general my feeling for the physics community is that there is somewhat of a split in attitudes as to the acceptance of machine learning methods. Some people are against it in favor of the more traditional "physics-based" modeling, and argue against the black-box nature of many machine learning models. Others are for it and have put it to good use. There's certainly no denying it's effectiveness in some very key areas. As more and more research is done into the subject, and the community-wide understanding of machine learning methods grows, it will make it's way into more and more applications.


<!-- While understanding the physical and mathematical motivations behind any utilized models will always be necessary, as more and more research is done into the subject and the community-wide understanding grows around machine learning methods, they will make their way into more and more applications.
 -->

Most of the active research has been done in the last few years, with some of the earliest examples going back ten years or so. **Supervised learning** models are primarily used, which is unsurprising to me as supervised learning is where every industry and application starts before moving on to unsupervised techniques. (It also aligns more directly with the hard-science nature of physics.) As for the techniques themselves, most of the earlier models were along the lines of decision tree ensembles, with one result of note using boosted decision trees being that of the discovery and measurement of the Higgs boson back in 2012. Nowadays however, most of the recent models are some type of neural network or other. 

<!-- physics is more of a deductive science than an inductive one
 -->

## Applications

From here on out I'll go through a few use cases. Keep in mind that the examples listed here are just scratch the surface. 

<!-- For a lot of my examples I've taken images and plots from various public papers and presentations and include the respective citations. -->



### Triggering / event selection via classification

If the experiments mentioned up above gathered all data that was produced, the data rate would be of order **peta-bytes of data per second**. In order to reduce this to a manageable level, giga-bytes per second (still a lot!), the data is filtered with various **trigger systems** which decide whether an event was important enough to keep or not. Most experiment trigger systems currently use traditional, hard-cut, techniques. Some like the LHCb experiment at CERN however use machine learning classification methods, and more are planning on doing so. The power and flexibility of these new methods open up new opportunities for improved data taking and selection. As any good scientist knows, getting the useful data is often the hardest part. And by improving the data pipeline at the very beginning, every stage later on is improved.


<!-- ![](/images/particle_investigation_blog/CMS_Event.png) -->

| ![](/images/particle_investigation_blog/CMS_Event.png) |
|:-------------------------:|
| Event display of a collision at the CMS experiment. |


<!-- 
The experiments at CERN all use or will use machine learning methods in their triggering systems. 


The LHCb experiment in particular uses machine learning in their trigg
 -->

<!-- a neural network to remove "fake" and uninteresting events. (And in general appears to be one of the fore-runner physics experiments in using machine learning in numerous ways.) The figures below show...
 --> -->


<!-- <p float="left">
  <img src="/images/particle_investigation_blog/LHCb_fakes.png" width="250" />
  <img src="/images/particle_investigation_blog/LHCb_backgroundrejection.png" width="250" /> 
</p> -->
<!-- http://cdsweb.cern.ch/record/2644895/files/Machine_learning_at_LHCb_-_Kazeev_-_v6%2023.10.pdf
 -->


<!-- 
| ![](/images/particle_investigation_blog/LHC_event_selection.png) |
|:-------------------------:|
| *event selection ...*| -->





### Particle and jet identification via classification

Beyond event selection, machine learning classification methods can be used for particle and jet identification. Detectors record a wealth of information as particles pass through them, and that information corresponds to particular signatures which can be used to identify and separate them. To go into a little more complexity, these classification algorithms can be applied to so-called **jets**. A jet is a shower of particles all originating from a single parent particle. As that parent particle passes through materials it will produce other particles, each of which will then produce it's own daughters, and so on until all the momentum is exhausted. The constituents of the jets and it's overall behavior will be dependent on the origin particles. The jet profiles for different sources can be recognized with image recognition techniques using convolutional neural networks.  Recurrent or recursive neural networks offer some interesting possibilities for identifying whether specific daughter particles are part of a jet or not. Machine learning methods have been put to good use in these areas, and there is a lot of on-going active research.




<!-- After a collision, many particles will be released with high momenta in a specific direction. As those particles travel outwards they will hit material creating new particles, decay to other particles, and so on with the daughters. This shower of particles is called a jet, and identifying whether data is related to a jet or not, and what the source is for a specific jet, is a prime example for the use of machine learning methods. The jet profiles below for different sources can be recognized with image recognition techniques using convolutional neural networks. Similarly, there is an analogy in the sequence of jet constituent particles to words in a sentence where the time-variation of the constituents provides valuable information, suggesting that recurrent or recursive neural networks might be useful. There is a lot of active research in these various areas.
 -->

<!-- ![](/images/particle_investigation_blog/LHCb_PID.png) -->

| <img src="/images/particle_investigation_blog/LHCb_PID.png" width="400" /> |
|:-------------------------:|
| Example architecture of particle identification at LHCb. [Source](http://cdsweb.cern.ch/record/2644895/files/Machine_learning_at_LHCb_-_Kazeev_-_v6%2023.10.pdf) |



<!-- 
| ![](/images/particle_investigation_blog/JetProfiles.png) |
|:-------------------------:|
| Example jet profiles which can be used with image recognition techniques. [Source](https://indico.in2p3.fr/event/17429/attachments/47800/62191/2018-06-22_ML_Introduction_Haake.pdf) | 
-->



<!-- ![](/images/particle_investigation_blog/JetProfiles.png) -->
<!-- https://indico.in2p3.fr/event/17429/attachments/47800/62191/2018-06-22_ML_Introduction_Haake.pdf
 -->



### Particle/event parameter estimation via regression

Of course, there are are many use cases for regression methods in particle physics. Parameters for particle measurements need to be evaluated either for the final analysis results or in the steps leading up to it. Classical regression methods have long been used to great success, but machine learning methods may offer new insights or power where this parameter estimation is difficult. One paper I ran across was from a group of researchers utilizing Bayesian neural networks to estimate simulated jet momenta and the respective statistical and systematic uncertainties on the extracted momenta. This last point deserves a bit more explanation, in that knowing the uncertainty on a measurement is just as important as the measurement itself, for without the former the latter is meaningless. Understanding how to determine measurement uncertainties dependent on the machine learning methods themselves is an active area of research. As this understanding grows and the black-box nature of these algorithms becomes less and less opaque, machine learning methods will only become more widespread.


| ![](/images/particle_investigation_blog/BayesianNN_momenta.png) |
|:-------------------------:|
| Example architecture of for a Bayesian neural network which extracts a particle's momentum and the associated error on it. [Source](https://arxiv.org/pdf/2003.11099.pdf) |



<!-- ![](/images/particle_investigation_blog/BayesianNN_momenta.png) -->
<!-- https://arxiv.org/pdf/2003.11099.pdf
 -->



### Faster simulation and detector reconstruction via GANs

As a last use case example, GANs (generative adversarial networks), can be used for **faster simulation** of particle distributions. A wide variety of particle distributions are constantly simulated as part of an experiment's workload. These simulations provide an extremely valuable tool for both testing algorithms and models before deployment, and gaining insights about the operation of the experiment and the final measurement. These simulations however usually take a very long time to produce, and I myself spent quite a bit of time simulating particle tracks that I could test a tracking algorithm on. This is due to both the statistics necessary to generate, usually upwards of a billion events, and the fact that every single event has to be processed independently, step-by-step. Geant4 is the current main framework for simulating particle distributions and is immensely powerful. While the code itself is not slow, the degree of complexity in simulating billions of physical interactions in an accurate manner adds up. GANs, because they can learn to generate data with the same distributions and statistics as the input samples, offer an attractive possibility to simulate these particle distributions in a way that is multiple orders of magnitude faster than Geant4. This could save thousands upon thousands of CPU hours, which is an incredibly valuable resource. 


<!--   This is currently used for a lot of image generation techniques, but the same principle can be applied to generating particle distributions. While kinks still have to be worked out, the opportunity for particle distribution generation that is multiple orders of magnitude faster than the current method would save thousands upon thousands of CPU (and by extension person) hours. -->


<!-- Before machine learning methods, this was the only way, since the accuracy of the simulation is often of the utmost importance. -->
<!--  the current main framework to simulate particle distributions, propagates particles in some simulation and does so step by step for every single particle as it passes through objects, decays, changes momentum, etc. As one could imagine, doing it step by step like this takes quite a while. 
 -->



| ![](/images/particle_investigation_blog/GAN_Simulation.png) |
|:-------------------------:|
| Comparison of Monte Carlo particle distributions generated with Geant4 versus a GAN model. [Source](https://indico.in2p3.fr/event/17429/attachments/47800/62191/2018-06-22_ML_Introduction_Haake.pdf) |


<!-- ![](/images/particle_investigation_blog/GAN_Simulation.png)
 --><!-- https://indico.in2p3.fr/event/17429/attachments/47800/62191/2018-06-22_ML_Introduction_Haake.pdf
 -->



## Summary


The use cases I've described here just barely scratch the surface. Beyond all the specific variations of the above categories, machine learning models can be used for anomaly detection for new physics, decorrelation methods, density estimation, track reconstruction, uncertainty quantification, data quality control and management, and many more. All in all, machine learning offers a wealth of potential improvement throughout particle physics. What was rare ten or so years ago is now becoming more common place and even vital. If an experimental result didn't use machine learning methods in it's final analysis, then it almost certainly used it somewhere upstream in an indirect way. As the years go by machine learning will makes it's way into more and more applications, and I'll be very interested to see what the landscape looks like ten years from now.


<!-- 
All in all, machine learning is being used more and more in particle physics as the years go by. What was rare ten or so years ago is now becoming more common place and even vital now. Many recent results in particle physics have used machine learning methods either in a direct or indirect way. The possible gains and improvements are still being understood and tested but the possibilities are there and researchers are working on them. I'll be very interested to see what the landscape looks like ten years from now. While machine learning wasn't part of the core curriculum when I was in graduate school several years ago, (there were touches on it here and there), I suspect it will makes it's way into the curriculum more formally. Indeed with the level of expertise needed to build the machine learning models appropriate for particle physics use cases, there may come a time when specific degree tracks are more aligned with it.

some final sentence to cap things off... -->


<!--  As more time passes and the possible gains and improvements become more understood by various researchers
 -->

<!-- maybe talk briefly about kaggle competitions?
 -->



<!-- ![](/images/particle_investigation_blog/Atlas_Jets.png) -->



Sources:
- [Living Review of Machine Learning for Particle Physics](https://iml-wg.github.io/HEPML-LivingReview/) - GitHub repository containing links to many, many papers on the subject
- [Introduction to Machine Learning in High-Energy Physics](https://indico.in2p3.fr/event/17429/attachments/47800/62191/2018-06-22_ML_Introduction_Haake.pdf) by R. Haake
- [Machine Learning at LHCb](http://cdsweb.cern.ch/record/2644895/files/Machine_learning_at_LHCb_-_Kazeev_-_v6%2023.10.pdf) by N. Kazeev
- [Machine Learning in Atalas](https://indico.cern.ch/event/673207/contributions/2755302/attachments/1560980/2457386/synpa_2017.pdf) by S. Thais
- [Machine Learning in Particle Physics](https://indico.fnal.gov/event/15893/contributions/34315/attachments/21384/26602/Fermilab_ML_Lecture1.pdf) by M. Williams




